print(missing_in_all_data)
missing_in_daily_data <- as.Date(missing_in_daily_data, origin = "1970-01-01")
missing_in_all_data <- as.Date(missing_in_all_data, origin = "1970-01-01")
print(missing_in_daily_data)
print(missing_in_all_data)
merged_data_no_leap_imputed <- merged_data_no_leap %>%
mutate(across(c(GLOB, LT), ~ na_kalman(.)))
ggplot_na_distribution(merged_data_no_leap_imputed)
merged_data_no_leap_imputed <- merged_data_no_leap_imputed %>%
arrange(DATO) %>%
distinct(DATO, .keep_all = TRUE)
library(ggplot2)
library(tidyr)
# Convert data to long format for easier plotting of multiple variables
merged_data_long <- merged_data_no_leap_imputed %>%
pivot_longer(cols = c(Forretning, Industri, Privat),
names_to = "Measurement", values_to = "Value")
ggplot(merged_data_long, aes(x = DATO, y = Value, color = Measurement)) +
geom_line() +
labs(title = "Raw Data Visualization for Measurements",
x = "Date",
y = "Value") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
merged_data_long2 <- merged_data_no_leap_imputed %>%
pivot_longer(cols = c(LT, GLOB),
names_to = "Measurement", values_to = "Value")
ggplot(merged_data_long2, aes(x = DATO, y = Value, color = Measurement)) +
geom_line() +
labs(title = "Raw Data Visualization for Measurements",
x = "Date",
y = "Value") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
min_max_scale <- function(x) {
(x - min(x, na.rm = TRUE)) / (max(x, na.rm = TRUE) - min(x, na.rm = TRUE))
}
# min-max scaling
merged_data_long <- merged_data_no_leap_imputed %>%
pivot_longer(cols = c(LT, GLOB, Forretning, Industri, Privat),
names_to = "Measurement", values_to = "Value") %>%
group_by(Measurement) %>%
mutate(Value_scaled = min_max_scale(Value))
ggplot(merged_data_long, aes(x = DATO, y = Value_scaled, color = Measurement)) +
geom_line() +
labs(title = "Scaled Data Visualization for Measurements",
x = "Date", y = "Scaled Value (0-1)") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
duplicates_in_data <- merged_data_no_leap_imputed %>%
filter(duplicated(DATO) | duplicated(DATO, fromLast = TRUE))
print(duplicates_in_data)
merged_data_clean <- merged_data_no_leap_imputed %>%
distinct(DATO, .keep_all = TRUE)
library(feasts)
library(tsibble)
merged_tsibble <- merged_data_clean %>%
as_tsibble(index = DATO)
# KPSS on GLOB
kpss_result_glob <- merged_tsibble %>%
features(GLOB, unitroot_kpss)
print("KPSS Test for GLOB:")
print(kpss_result_glob)
# KPSS on LT
kpss_result_lt <- merged_tsibble %>%
features(LT, unitroot_kpss)
print("KPSS Test for LT:")
print(kpss_result_lt)
# KPSS on Forretning
kpss_result_forretning <- merged_tsibble %>%
features(Forretning, unitroot_kpss)
print("KPSS Test for Forretning:")
print(kpss_result_forretning)
# KPSS on Industri
kpss_result_industri <- merged_tsibble %>%
features(Industri, unitroot_kpss)
print("KPSS Test for Industri:")
print(kpss_result_industri)
# KPSS on Privat
kpss_result_privat <- merged_tsibble %>%
features(Privat, unitroot_kpss)
print("KPSS Test for Privat:")
print(kpss_result_privat)
which(is.na(merged_data_clean))
merged_data_clean[which(is.na(merged_data_clean)), ]
merged_data_clean <- merged_data_clean %>% na.omit()
# function to calculate max cross-correlation for each pair
cross_correlation_matrix <- function(data) {
variable_names <- colnames(data)
results <- expand.grid(var1 = variable_names, var2 = variable_names)
results <- results %>% filter(var1 != var2)
results <- results %>%
rowwise() %>%
mutate(
max_ccf = max(abs(ccf(data[[var1]], data[[var2]], plot = FALSE)$acf), na.rm = TRUE),
max_lag = which.max(abs(ccf(data[[var1]], data[[var2]], plot = FALSE)$acf)) - 1
)
return(results)
}
merged_data_values <- merged_data_clean %>%
select(-DATO)
ccf_results <- cross_correlation_matrix(merged_data_values)
print(ccf_results)
ggplot(ccf_results, aes(x = var1, y = var2, fill = max_ccf)) +
geom_tile() +
scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0.5) +
labs(title = "Cross-Correlation Between Variables",
x = "", y = "", fill = "Max CCF") +
theme_minimal()
plot_acf_pacf_short <- function(data, column_name) {
cat("Plotting ACF and PACF for", column_name, "short-term (14 days)\n")
acf(data[[column_name]], lag.max = 14, main = paste("ACF of", column_name, "(Short-term)"))
pacf(data[[column_name]], lag.max = 14, main = paste("PACF of", column_name, "(Short-term)"))
}
plot_acf_pacf_long <- function(data, column_name) {
cat("Plotting ACF and PACF for", column_name, "long-term (2 years)\n")
acf(data[[column_name]], lag.max = 730, main = paste("ACF of", column_name, "(Long-term)"))
pacf(data[[column_name]], lag.max = 730, main = paste("PACF of", column_name, "(Long-term)"))
}
columns_to_analyze <- c("GLOB", "LT", "Forretning", "Industri", "Privat")
for (col in columns_to_analyze) {
plot_acf_pacf_short(merged_data_clean, col)
plot_acf_pacf_long(merged_data_clean, col)
}
seasonally_differenced_data <- merged_tsibble %>%
mutate(across(c(GLOB, LT, Forretning, Industri, Privat),
~ difference(.x, lag = 365))) %>%
filter(!is.na(rowSums(across(c(GLOB, LT, Forretning, Industri, Privat)))))
for (col in columns_to_analyze) {
plot_acf_pacf_short(seasonally_differenced_data, col)
plot_acf_pacf_long(seasonally_differenced_data, col)
}
convert_to_ts <- function(data, start_year = 2021, start_day = 1, frequency = 365) {
# Ensure `data` is a data.frame
data <- as.data.frame(data)
# Initialize an empty list to store time series columns
ts_list <- list()
# Loop over each column in the data frame
for (col_name in names(data)) {
# Check if the column is numeric (to be converted to time series)
if (is.numeric(data[[col_name]])) {
# Convert column to time series with specified frequency
ts_list[[col_name]] <- ts(data[[col_name]],
frequency = frequency,
start = c(start_year, start_day))
} else {
# If not numeric, keep the column as it is (e.g., Date column)
ts_list[[col_name]] <- data[[col_name]]
}
}
# Convert the list to a data frame
ts_data <- as.data.frame(ts_list)
# Return the data frame with time series columns
return(ts_data)
}
merged_data_ts <- convert_to_ts(merged_data_clean)
perform_stl_on_all_columns <- function(data, date_column = "DATO", frequency = 365) {
# Ensure `data` is a data.frame
data <- as.data.frame(data)
# Initialize an empty list to store STL decomposition results
stl_results <- list()
# Loop over each column in the data frame
for (col_name in names(data)) {
# Skip the date column
if (col_name != date_column && is.numeric(data[[col_name]])) {
# Convert the column to a time series with the specified frequency
ts_column <- ts(data[[col_name]], frequency = frequency)
# Perform STL decomposition on the time series column
stl_result <- stl(ts_column, s.window = "periodic")
# Store the result in the list with the column name as key
stl_results[[col_name]] <- stl_result
}
}
# Return the list of STL decomposition results
return(stl_results)
}
stl_decompositions <- perform_stl_on_all_columns(merged_data_clean)
# Define a function to plot and extract STL components for each column in stl_decompositions
plot_and_extract_stl_components <- function(stl_decompositions) {
components <- list()
# Loop through each decomposition in the list
for (col_name in names(stl_decompositions)) {
# Access the STL decomposition for the specific column
stl_result <- stl_decompositions[[col_name]]
# Plot the decomposition
cat("Plotting STL decomposition for:", col_name, "\n")
plot(stl_result, main = paste("STL Decomposition for", col_name))
# Extract individual components
seasonal_component <- stl_result$time.series[, "seasonal"]
trend_component <- stl_result$time.series[, "trend"]
remainder_component <- stl_result$time.series[, "remainder"]
components[[col_name]] <- list(seasonal = seasonal_component,
trend = trend_component,
remainder = remainder_component)
}
return(components)
}
list_comps <- plot_and_extract_stl_components(stl_decompositions)
# Initialize empty lists to store each component for all variables
seasonal_data <- list()
trend_remainder_data <- list()
# Loop over each variable in list_comps
for (var_name in names(list_comps)) {
# Extract the components for the current variable
seasonal_component <- list_comps[[var_name]]$seasonal
trend_component <- list_comps[[var_name]]$trend
remainder_component <- list_comps[[var_name]]$remainder
# Store the seasonal component in the seasonal_data list
seasonal_data[[var_name]] <- seasonal_component
# Store the sum of trend and remainder in the trend_remainder_data list
trend_remainder_data[[var_name]] <- trend_component + remainder_component
}
# Convert the lists to data frames
seasonal_df <- as.data.frame(seasonal_data)
trend_remainder_df <- as.data.frame(trend_remainder_data)
# Add row names as Date if available (assuming the same length and that you have dates)
# If you have a separate vector of dates, you can add it as a Date column.
dates <- merged_data_ts$DATO # Uncomment and define your dates if needed
seasonal_df$Date <- dates
trend_remainder_df$Date <- dates
# Print or check the data frames
head(seasonal_df)
head(trend_remainder_df)
ts_trend_reminder <- as_tsibble(trend_remainder_df)
deseasoned_data_ts <- ts(trend_remainder_df, frequency = 365)
original_data_ts <- ts(merged_tsibble, frequency = 365)
library(vars)
# For original data
lag_selection_orig <- VARselect(original_data_ts, lag.max = 15, type = "const")
lag_order_orig <- lag_selection_orig$selection["AIC(n)"]
# For deseasoned data
lag_selection_deseason <- VARselect(deseasoned_data_ts, lag.max = 15, type = "const")
lag_order_deseason <- lag_selection_deseason$selection["AIC(n)"]
var_model_orig <- VAR(original_data_ts, p = lag_order_orig, type = "const")
var_model_deseason <- VAR(deseasoned_data_ts, p = lag_order_deseason, type = "const")
# LT
granger_test_orig <- causality(var_model_orig, cause = "LT")
print(granger_test_orig)
granger_test_deseason <- causality(var_model_deseason, cause = "LT")
print(granger_test_deseason)
# GLOB
granger_test_orig <- causality(var_model_orig, cause = "GLOB")
print(granger_test_orig)
granger_test_deseason <- causality(var_model_deseason, cause = "GLOB")
print(granger_test_deseason)
# Forretning
granger_test_orig <- causality(var_model_orig, cause = "Forretning")
print(granger_test_orig)
granger_test_deseason <- causality(var_model_deseason, cause = "Forretning")
print(granger_test_deseason)
# Industri
granger_test_orig <- causality(var_model_orig, cause = "Industri")
print(granger_test_orig)
granger_test_deseason <- causality(var_model_deseason, cause = "Industri")
print(granger_test_deseason)
# Privat
granger_test_orig <- causality(var_model_orig, cause = "Privat")
print(granger_test_orig)
granger_test_deseason <- causality(var_model_deseason, cause = "Privat")
print(granger_test_deseason)
library(forecast)
rmse <- function(predicted, actual) {
sqrt(mean((predicted - actual)^2))
}
# Function given in the assignment description
CV.2 <- function(data, model_fct, init_fold = 1096 - 90 * 5, h = 90, return_models = FALSE, ...) {
fold_inds <- seq(init_fold, length(data) - h, by = h)
rmse <- c()
models <- list()
for (i in seq_along(fold_inds)) {
fold <- fold_inds[i]
train <- data[1:(fold - 1)]
test <- data[fold:(fold + h - 1)]
new_model <- model_fct(train, ...)
models[[i]] <- new_model
forecast <- forecast(new_model, h = h)
rmse <- c(rmse, rmse(forecast$mean, test))
}
if (return_models) {
return(list(rmse = rmse, model = models))
} else {
return(rmse)
}
}
forecast_Privat <- CV.2(seasonally_differenced_data$Privat, model_fct = auto.arima, return_models = TRUE)
print(forecast_Privat)
forecast_LT <- CV.2(seasonally_differenced_data$LT, model_fct = auto.arima, return_models = TRUE)
print(forecast_LT)
forecast_GLOB <- CV.2(seasonally_differenced_data$GLOB, model_fct = auto.arima, return_models = TRUE)
print(forecast_GLOB)
rmse_results <- data.frame(
Variable = c("Privat", "LT", "GLOB"),
RMSE = c(mean(forecast_Privat), mean(forecast_LT), mean(forecast_GLOB))
)
ggplot(rmse_results, aes(x = Variable, y = RMSE)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Average RMSE for Each Variable", y = "Average RMSE", x = "Variable")
residuals_Privat <- residuals(forecast_Privat$model[[1]])
shapiro_test <- shapiro.test(residuals_Privat)
print(shapiro_test)
residuals_LT <- residuals(forecast_LT$model[[1]])
shapiro_test <- shapiro.test(residuals_LT)
print(shapiro_test)
forecast_Privat <- CV.2(merged_data_ts$Privat, model_fct = auto.arima, return_models = TRUE)
print(forecast_Privat)
forecast_LT <- CV.2(merged_data_ts$LT, model_fct = auto.arima, return_models = TRUE)
print(forecast_LT)
forecast_GLOB <- CV.2(merged_data_ts$GLOB, model_fct = auto.arima, return_models = TRUE)
print(forecast_GLOB)
rmse_results <- data.frame(
Variable = c("Privat", "LT", "GLOB"),
RMSE = c(mean(forecast_Privat), mean(forecast_LT), mean(forecast_GLOB))
)
ggplot(rmse_results, aes(x = Variable, y = RMSE)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Average RMSE for Each Variable", y = "Average RMSE", x = "Variable")
residuals_Privat <- residuals(forecast_Privat$model[[1]])
shapiro_test <- shapiro.test(residuals_Privat)
print(shapiro_test)
residuals_LT <- residuals(forecast_LT$model[[1]])
shapiro_test <- shapiro.test(residuals_LT)
print(shapiro_test)
residuals_GLOB <- residuals(forecast_GLOB$model[[1]])
shapiro_test <- shapiro.test(residuals_GLOB)
print(shapiro_test)
# Backcast for Privat (air temperature)
forecast_Privat_backcast <- CV_backcast(merged_data_ts$Privat, model_fct = auto.arima, return_models = TRUE)
# Function for backcasting
CV_backcast <- function(data, model_fct, init_fold = length(data), h = 1, return_models = FALSE, ...) {
fold_inds <- seq(init_fold, 1, by = -h)  # Backcast in reverse order (from 2021 to 2017)
rmse_values <- c()
models <- list()
for (i in seq_along(fold_inds)) {
fold <- fold_inds[i]
# Train on the available data (up to the current fold index)
train <- data[1:(fold - 1)]
# Apply the model to the training data
new_model <- model_fct(train, ...)
models[[i]] <- new_model
# Forecast for the previous year (backcasting)
forecast <- forecast(new_model, h = h)
# Collect RMSE for backcasting
if (i < length(fold_inds)) {  # Skip the first backcast as there's no true value for it
test <- data[(fold - h):(fold - 1)]  # Actual data for the previous year
rmse_values <- c(rmse_values, rmse(forecast$mean, test))
}
}
if (return_models) {
return(list(rmse = rmse_values, model = models))
} else {
return(rmse_values)
}
}
# Backcast for Privat (air temperature)
forecast_Privat_backcast <- CV_backcast(merged_data_ts$Privat, model_fct = auto.arima, return_models = TRUE)
# Backcast for LT (air temperature)
forecast_LT_backcast <- CV_backcast(merged_data_ts$LT, model_fct = auto.arima, return_models = TRUE)
# Backcast for GLOB (global irradiation)
forecast_GLOB_backcast <- CV_backcast(merged_data_ts$GLOB, model_fct = auto.arima, return_models = TRUE)
# Print the results
print(forecast_Privat_backcast)
print(forecast_LT_backcast)
print(forecast_GLOB_backcast)
# Visualize the RMSE for each variable
rmse_results_backcast <- data.frame(
Variable = c("Privat", "LT", "GLOB"),
RMSE = c(mean(forecast_Privat_backcast), mean(forecast_LT_backcast), mean(forecast_GLOB_backcast))
)
ggplot(rmse_results_backcast, aes(x = Variable, y = RMSE)) +
geom_bar(stat = "identity") +
theme_minimal() +
labs(title = "Average RMSE for Each Backcasted Variable", y = "Average RMSE", x = "Variable")
library(ggplot2)
# Combine the backcasted forecast results with the actual data
# Assuming the backcasted data for each year is stored in 'forecast_Privat_backcast', 'forecast_LT_backcast', 'forecast_GLOB'
# You need to prepare a time series for both forecasted (backcasted) and actual values
# Assuming the following format:
# forecast_Privat_backcast$forecast contains forecasted values
# merged_data_ts$Privat contains actual values for 2021 onward
# For the backcasted years (2017-2020), create a data frame with the forecasted values
backcast_years <- 2017:2020
forecast_Privat_values <- forecast_Privat_backcast$model[[1]]$mean  # Extract forecast values for Privat
forecast_LT_values <- forecast_LT_backcast$model[[1]]$mean  # Extract forecast values for LT
forecast_GLOB_values <- forecast_GLOB_backcast$model[[1]]$mean  # Extract forecast values for GLOB
# Actual values from 2021 onward
actual_Privat_values <- merged_data_ts$Privat[1:length(forecast_Privat_values)]
actual_LT_values <- merged_data_ts$LT[1:length(forecast_LT_values)]
actual_GLOB_values <- merged_data_ts$GLOB[1:length(forecast_GLOB_values)]
# Combine the forecasted and actual values into a single data frame for plotting
df <- data.frame(
Year = rep(backcast_years, each = 3),
Variable = rep(c("Privat", "LT", "GLOB"), times = length(backcast_years)),
Value = c(forecast_Privat_values, forecast_LT_values, forecast_GLOB_values)
)
# Check the forecast results to confirm the extracted values
print(forecast_Privat$model[[1]])  # For Privat
print(forecast_LT$model[[1]])  # For LT
print(forecast_GLOB$model[[1]])  # For GLOB
# Now extract the forecasted values from each model
forecast_Privat_values <- forecast_Privat$model[[1]]$mean  # Extract forecasted values
forecast_LT_values <- forecast_LT$model[[1]]$mean  # Extract forecasted values
forecast_GLOB_values <- forecast_GLOB$model[[1]]$mean  # Extract forecasted values
# Check the length of forecasted values to make sure they are correct
print(length(forecast_Privat_values))  # Should be 4 for each of the 4 years
print(length(forecast_LT_values))  # Should be 4
print(length(forecast_GLOB_values))  # Should be 4
# If the length is correct, proceed to create the data frame for backcasted years
backcast_years <- 2017:2020  # Forecasting for 4 years (2017-2020)
df <- data.frame(
Year = rep(backcast_years, each = 3),  # 3 variables (Privat, LT, GLOB)
Variable = rep(c("Privat", "LT", "GLOB"), times = length(backcast_years)),
Value = c(forecast_Privat_values, forecast_LT_values, forecast_GLOB_values)
)
# Check the forecast objects to confirm the forecast results
print(forecast_Privat$model[[1]])  # Print the ARIMA model for Privat
print(forecast_LT$model[[1]])  # Print the ARIMA model for LT
print(forecast_GLOB$model[[1]])  # Print the ARIMA model for GLOB
# Extract forecasted values (mean) for each model
forecast_Privat_values <- forecast_Privat$model[[1]]$mean  # Extract forecasted values
forecast_LT_values <- forecast_LT$model[[1]]$mean  # Extract forecasted values
forecast_GLOB_values <- forecast_GLOB$model[[1]]$mean  # Extract forecasted values
# Check the length of the forecasted values
print(length(forecast_Privat_values))  # Should match the length of backcast_years
print(length(forecast_LT_values))  # Should match the length of backcast_years
print(length(forecast_GLOB_values))  # Should match the length of backcast_years
# Backcast for years 2017-2020 (ensure you're backcasting to 2017)
backcast_years <- 2017:2020
# Create a data frame with backcasted values
df <- data.frame(
Year = rep(backcast_years, each = 3),  # 3 variables (Privat, LT, GLOB)
Variable = rep(c("Privat", "LT", "GLOB"), times = length(backcast_years)),
Value = c(forecast_Privat_values, forecast_LT_values, forecast_GLOB_values)
)
residuals_Privat <- residuals(forecast_Privat$model[[1]])
shapiro_test <- shapiro.test(residuals_Privat)
print(shapiro_test)
residuals_LT <- residuals(forecast_LT$model[[1]])
shapiro_test <- shapiro.test(residuals_LT)
print(shapiro_test)
residuals_GLOB <- residuals(forecast_GLOB$model[[1]])
shapiro_test <- shapiro.test(residuals_GLOB)
print(shapiro_test)
residuals_Privat <- residuals(forecast_Privat_backcast$model[[1]])
shapiro_test <- shapiro.test(residuals_Privat)
print(shapiro_test)
residuals_LT <- residuals(forecast_LT_backcast$model[[1]])
shapiro_test <- shapiro.test(residuals_LT)
print(shapiro_test)
residuals_Privat <- residuals(forecast_Privat$model[[1]])
shapiro_test <- shapiro.test(residuals_Privat)
print(shapiro_test)
residuals_LT <- residuals(forecast_LT$model[[1]])
shapiro_test <- shapiro.test(residuals_LT)
print(shapiro_test)
residuals_Privat <- residuals(forecast_Privat$model[[1]])
shapiro_test <- shapiro.test(residuals_Privat)
print(shapiro_test)
residuals_LT <- residuals(forecast_LT$model[[1]])
shapiro_test <- shapiro.test(residuals_LT)
print(shapiro_test)
library(forecast)
# Prepare your data
# Assume merged_data_ts is your time series data frame
target <- merged_data_ts$GLOB  # Global Irradiation (target variable)
exogenous <- merged_data_ts$Privat  # Exogenous variable (could be another time series)
# Fit the ARIMAX model (auto.arima automatically selects the best ARIMA model)
arimax_model <- auto.arima(target, xreg = exogenous)
# Forecast the next 90 days (for example)
forecast_horizon <- 1  # For forecasting the next 90 days
forecast_values <- forecast(arimax_model, h = forecast_horizon, xreg = exogenous)
# Plot the forecast
plot(forecast_values)
library(forecast)
# Prepare your data
# Assume merged_data_ts is your time series data frame
target <- merged_data_ts$GLOB  # Global Irradiation (target variable)
exogenous <- merged_data_ts$Privat  # Exogenous variable (could be another time series)
# Fit the ARIMAX model (auto.arima automatically selects the best ARIMA model)
arimax_model <- auto.arima(target, xreg = exogenous)
# Forecast the next 90 days (for example)
forecast_horizon <- 1  # For forecasting the next 90 days
forecast_values <- forecast(arimax_model, h = forecast_horizon, xreg = exogenous)
# Plot the forecast
plot(forecast_values)
library(dplyr)
library(readr)
library(lubridate)
library(tidyverse)
library(tidyr)
library(ggplot2)
library(imputeTS)
?read.csv2()
elhub <- read.csv2("consumption_per_group_aas_hour.csv")
elhub <- elhub %>%
mutate(STARTTID = ymd_hms(STARTTID, tz = "Europe/Oslo"))
elhub <- elhub %>%
select(STARTTID, FORBRUKSGRUPPE, VOLUM_KWH)
library(dplyr)
library(readr)
library(lubridate)
library(tidyverse)
library(tidyr)
library(ggplot2)
library(imputeTS)
?read.csv2()
elhub <- read.csv2("consumption_per_group_aas_hour.csv")
elhub <- elhub %>%
mutate(STARTTID = ymd_hms(STARTTID, tz = "Europe/Oslo"))
elhub <- elhub %>%
select(STARTTID, FORBRUKSGRUPPE, VOLUM_KWH)
